
# 1) Developer Directions (Plain-English Overview & Step‑by‑Step)

## What is the CORTEX Context Profile (CCP)?

A **short questionnaire** (12 items, \~4 minutes) that captures the **operating context** of a company or business unit (e.g., how regulated they are, how sensitive their data is, how fast their market moves, etc.). It produces a small vector of numbers/flags.

## Why is it important?

We use this profile to **tailor the CORTEX program** so leaders get **relevant gates, priorities, and examples**. It makes recommendations safer and faster **without changing their raw readiness scores**.

## What the CCP **does**

1. **Enforces “gates” (non‑negotiables)** before a company scales AI (e.g., “you must have incident response + human‑in‑the‑loop given your risk level”).
2. **Orders the “Next 2 Moves”** we recommend for each weak domain (e.g., in a regulated bank, Risk moves outrank Experimentation).
3. **Routes content** (examples, KPIs, policy templates) that match the org’s context.
4. **Tunes Buy‑vs‑Build** weights (e.g., emphasize compliance in regulated settings).

## What the CCP **does NOT** do

* **Does not change** the CORTEX pillar scores from the pulse questions.
* **Does not hide logic**: any gate or priority should show *why* it was applied.
* **Does not store sensitive data by default** (no PII in free text; store answers as small integers/booleans).

## Where CCP fits in the overall flow

1. **Onboarding:** user completes the 12‑question profile (per org or per BU).
2. **Pulse Check (18 Yes/No):** collect readiness scores for the 6 pillars (C, O, R, T, E, X).
3. **Results:** show the Honeycomb view (scores), then apply CCP to:

   * Show **required gates** they must satisfy before scaling.
   * **Rank** recommended “Next 2 Moves” per weak pillar.
   * Route **sector‑relevant examples** and **policy templates**.
   * Prefill **Buy‑vs‑Build** weights for the DECIDE tool.
4. **Decision Studio:** user picks two moves per weak pillar; CCP explains why those are prioritized.
5. **Exports:** include profile, gates, chosen moves, and rationale.

## Guardrails the software must respect

* **Transparency:** Every gate and recommendation returned by the backend includes an `explain` field (what profile dimensions triggered it).
* **No score distortion:** Pillar scores come only from the pulse; CCP never alters them.
* **Override‑friendly:** Facilitators can toggle a gate off (with reason) and re‑rank moves.
* **Per‑BU support:** Each business unit can have its own profile; an enterprise view aggregates without weights.
* **Privacy:** Store profile as integers/booleans. Evidence uploads are optional, encrypted at rest, and never shared across orgs.

## What to build first (MVP order)

1. **Profile UI** (12 questions, sliders/yes‑no) + save API.
2. **Gate engine** (evaluate predicates → return required gate tasks with explanations).
3. **Priority engine** (rank “Next 2 Moves” using profile‑based weights; include explanations).
4. **Buy‑vs‑Build weight preset** for the DECIDE tool.
5. **Honeycomb view** remains as is; just display gates and prioritized moves alongside it.
6. **Export** (PDF/JSON) including scores, profile, gates, moves.

---

# 2) Technical Specification Document (for Engineering)

> **Purpose:** Implement the CORTEX Context Profile so it **gates**, **prioritizes**, **routes content**, and **tunes Buy‑vs‑Build**, without modifying pillar scores.

---

## A. Data Model

### A1. Profile vector (per Org **and** per BU)

```json
{
  "profile": {
    "regulatory_intensity": 0,        // 0..4
    "data_sensitivity": 0,            // 0..4
    "safety_criticality": 0,          // 0..4
    "brand_exposure": 0,              // 0..4
    "clock_speed": 0,                 // 0..4
    "latency_edge": 0,                // 0..4
    "scale_throughput": 0,            // 0..4
    "data_advantage": 0,              // 0..4
    "build_readiness": 0,             // 0..4
    "finops_priority": 0,             // 0..4
    "procurement_constraints": false, // boolean
    "edge_operations": false,         // boolean
    "functional_focus": ["Ops","CS"], // top 3 functions to transform (optional)
    "labels": ["Health","Public"]     // optional for copy/benchmarks
  }
}
```

### A2. Pillar scores (from Pulse 18; do not change)

```json
{
  "scores": { "C": 2, "O": 1, "R": 3, "T": 2, "E": 1, "X": 1 } // 0..3 per pillar
}
```

### A3. Recommendation object (backend → UI)

```json
{
  "gates": [
    {
      "id": "require_hitl",
      "pillar": "O",
      "title": "Human-in-the-Loop required for high-impact decisions",
      "reason": "High safety/regulation",
      "explain": { "safety_criticality": 3, "regulatory_intensity": 4 },
      "status": "unmet", // unmet | met | overridden
      "how_to": ["link:policy_hitl", "link:workflow_examples"]
    }
  ],
  "next_moves": [
    {
      "id": "add_incident_runbook",
      "pillar": "R",
      "title": "Publish AI incident response runbook",
      "rank": 1,
      "base_score": 0.70,
      "priority_boost": 0.18,
      "explain": { "regulatory_intensity": 4, "brand_exposure": 3 },
      "why_it_matters": "Your profile indicates audited regimes and PR risk.",
      "playbook": ["link:runbook_template", "link:tabletop_exercise"]
    }
  ],
  "decide_weights": { "Differentiation": 3, "Economics": 3, "Compliance": 3, "Implementation": 2, "Data": 3, "Evolution": 2 },
  "content_tags": ["regulated","high_safety","ops_first"]
}
```

---

## B. Profile Questionnaire (copy + anchors)

> Rate 0–4 unless Yes/No. Anchors must be shown in the UI.

**Risk & Constraints**

1. **Regulatory intensity:** 0 none · 1 guidance · 2 some rules · 3 audited/prescriptive · 4 heavily regulated/multi‑regime
2. **Data sensitivity & residency:** 0 public · 1 internal · 2 confidential · 3 PII/trade secrets · 4 PHI/PCI + in‑region required
3. **Safety/mission criticality:** 0 low harm · 1 inconvenience · 2 costly mistakes · 3 serious legal/financial · 4 physical safety/systemic risk
4. **Brand/PR exposure:** 0 tolerant · 1 minor · 2 meaningful · 3 major · 4 existential if wrong

**Business Dynamics**
5\. **Market/tech clock‑speed:** 0 annual · 1 quarterly · 2 monthly · 3 weekly · 4 frontier pace
6\. **Latency/edge dependence:** 0 seconds ok · 1 <1s · 2 <500ms · 3 <200ms · 4 offline/edge/air‑gapped
7\. **Scale/throughput:** 0 small internal · 1 dept · 2 enterprise · 3 high‑traffic · 4 hyperscale

**Advantage & Readiness**
8\. **Proprietary data advantage:** 0 none · 1 small · 2 moderate · 3 strong · 4 large, rights‑clear, labeled/fresh
9\. **Build readiness:** 0 none · 1 early pilots · 2 basics in place · 3 mature CoE/MLOps/IR · 4 industrialized
10\. **FinOps priority:** 0 low · 1 med‑low · 2 medium · 3 high · 4 strict per‑unit budgets

**Procurement & Org (Yes/No)**
11\. **Procurement constraints:** public RFP/mandatory vendor rules? Yes/No
12\. **Edge operations:** OT/SCADA, field robots/vehicles? Yes/No

**Optional:** choose up to 3 **functional focus** and optional **sector labels** (for examples/benchmarks only).

---

## C. Gate Engine (non‑negotiables)

**Principle:** Gates **block “scale” recommendations** until satisfied. They **do not change scores**.

**Rules (default thresholds; make configurable):**

* **G1 – HITL required:** if `regulatory_intensity >= 3` OR `safety_criticality >= 3` → enforce Human‑in‑the‑Loop for high‑impact decisions.
* **G2 – Assurance cadence:** if `regulatory_intensity >= 3` → require **R2** monthly (fairness/privacy/drift + red‑team) and **R3** annual internal/external review.
* **G3 – Data residency & retention:** if `data_sensitivity >= 3` → forbid data egress; require regional processing; default retention caps (e.g., 30 days).
* **G4 – Latency fallback:** if `latency_edge >= 3` → require p95 SLO (≤200ms) and tested failover (backup model/edge cache).
* **G5 – Scale hardening:** if `scale_throughput >= 3` → require load tests, rate‑limit plans, and dual‑region/vendor readiness.
* **G6 – Build readiness gate:** if `build_readiness <= 1` → block **heavy fine‑tune/pretrain** paths; suggest Buy→RAG→Light FT plus readiness upgrades (MLOps/IR/governance).
* **G7 – Procurement:** if `procurement_constraints == true` → attach public procurement templates; adjust timeline estimates.
* **G8 – Edge ops:** if `edge_operations == true` → advise OT security patterns, offline modes, and change‑management for field ops.

**Backend pseudo‑logic:**

```ts
function evaluateGates(p: Profile): Gate[] {
  const gates: Gate[] = [];
  if (p.regulatory_intensity >= 3 || p.safety_criticality >= 3) gates.push(G_HITL);
  if (p.regulatory_intensity >= 3) gates.push(G_ASSURANCE);
  if (p.data_sensitivity >= 3) gates.push(G_DATA_RESIDENCY);
  if (p.latency_edge >= 3) gates.push(G_LATENCY_FALLBACK);
  if (p.scale_throughput >= 3) gates.push(G_SCALE_HARDENING);
  if (p.build_readiness <= 1) gates.push(G_BUILD_BLOCK_HEAVY);
  if (p.procurement_constraints) gates.push(G_PROCUREMENT);
  if (p.edge_operations) gates.push(G_EDGE_OPS);
  return gates.map(g => attachExplain(g, p));
}
```

---

## D. Priority Engine (ranking “Next 2 Moves”)

**Principle:** Do **not** modify pillar scores. Use **small, transparent weights** to **rank** moves.

### D1. Inputs

* `scores`: pillar maturity (0..3).
* `profile`: the 12 answers.
* `moves`: library of actionable steps; each move has a `pillar` and **tags** indicating which profile dimensions it responds to.
  Example move: `add_incident_runbook` → pillar `R`, tags `["regulatory","brand","build_readiness_low"]`, base\_score `0.70`.

### D2. Weight table (default; make configurable)

| Profile dimension        | Affects pillars | Weight impact                                     |
| ------------------------ | --------------- | ------------------------------------------------- |
| High regulation / safety | R, O            | +0.08 each on R/O‑tagged moves                    |
| High data sensitivity    | R, O            | +0.06 (governance, DLP, residency)                |
| High brand exposure      | R, C            | +0.05                                             |
| High clock‑speed         | X, E            | +0.07                                             |
| High latency/edge        | O, E            | +0.06 (edge/latency moves)                        |
| High scale/throughput    | O, E            | +0.06 (load, rate‑limit, dual‑region)             |
| Strong data advantage    | O, X            | +0.07 (RAG, eval harness, light FT gates)         |
| Low build readiness      | C, T            | +0.07 (operating model, job redesign, enablement) |
| High finops priority     | E               | +0.05 (cost controls/quotas/FinOps)               |

### D3. Ranking formula

```
priority = base_score
         + stage_gap_boost
         + sum(profile_boosts by tag)

where:
  stage_gap_boost = 0.02 * (3 - pillar_stage)   // bigger boost if pillar is weaker
  profile_boosts  = weights mapped from profile to move tags (see table)
```

Return the top N per weak pillar, include `explain` showing which dimensions boosted it.

**Backend pseudo‑logic:**

```ts
function rankMoves(moves: Move[], scores: Scores, p: Profile): Move[] {
  return moves.map(m => {
    const gapBoost = 0.02 * (3 - scores[m.pillar]);
    const profBoost = sumBoostsFromProfile(m.tags, p); // per table above
    const priority = m.base_score + gapBoost + profBoost;
    return { ...m, priority, explain: {gapBoost, profBoost} };
  }).sort((a,b) => b.priority - a.priority);
}
```

---

## E. Content Routing

Attach `content_tags` based on profile; the UI uses tags to pull examples/templates:

* `regulated`, `high_safety`, `high_sensitivity`, `edge`, `hyperscale`, `data_advantage`, `low_readiness`, `finops_strict`, `public_procurement`.

Use tags to:

* Filter **case studies** and **KPIs** displayed.
* Load **policy snippets** (DLP, retention, model card templates) and **SLA baselines**.
* Prefill the **DECIDE** (Buy‑vs‑Build) weightings.

---

## F. Buy‑vs‑Build Presets (DECIDE)

Set initial weights by profile (editable in UI):

* If `regulatory_intensity >= 3` OR `data_sensitivity >= 3` → weight **Compliance** = 3 (max).
* If `clock_speed >= 3` → weight **Economics & Speed** higher.
* If `data_advantage >= 3` → weight **Differentiation** and **Data** higher.
* If `build_readiness <= 1` → lower **Implementation** weight; recommend **Buy → RAG**.

Return a `decide_weights` object with integers 1..3 for each DECIDE dimension.

---

## G. API Endpoints (suggested)

* `POST /api/profile` – create/update profile; body = profile vector; returns saved profile + computed gates/content tags/decide\_weights.
* `GET /api/profile` – fetch profile.
* `POST /api/gates/evaluate` – body = profile; returns gate list with `status` and `explain`.
* `POST /api/moves/rank` – body = { scores, profile }; returns ordered move list with `priority` and `explain`.
* `POST /api/decide/weights` – body = profile; returns DECIDE weights.
* `GET /api/content/tags` – body = profile; returns content tags for routing.

---

## H. UX Requirements

* Show **why**: every gate and ranked move must display `Because…` with the triggering dimensions.
* **Override & annotate**: facilitator can mark a gate as “overridden” with a reason; persist this.
* **Multiple profiles**: allow per‑BU profiles; an enterprise roll‑up must show unweighted pillar scores.
* **Accessibility**: all controls keyboard‑navigable; WCAG AA colors; plain language tooltips for terms (CoE, HITL, MLOps, SLA, RACI).
* **Internationalization**: keep copy strings centralized.

---

## I. Security & Privacy

* Store profile values as integers/booleans; avoid free‑text.
* Encrypt evidence files at rest; scope access to org/BU.
* No cross‑org benchmarks unless cohort size ≥ 25 (k‑anonymity).
* Provide hard delete on request.

---

## J. Telemetry (to improve the product)

Log events (no PII):
`profile.saved`, `gates.viewed`, `gate.overridden`, `moves.viewed`, `move.selected`, `decide.run`, `export.created`.
Use to refine weight defaults and content routing.

---

## K. Acceptance Criteria (MVP)

1. Saving a 12‑question profile returns a gate list and explains each gate.
2. Ranking moves changes when profile sliders change, and the UI shows the reason.
3. Pillar scores never change when profile changes.
4. Buy‑vs‑Build weights reflect profile; users can edit them.
5. Export includes: profile JSON, pillar scores, gates (with statuses), top moves (with explanations).

---

## L. Test Cases

* **High‑regulation scenario**: `regulatory_intensity=4`, `safety_criticality=3` → expect G1/G2 gates; R‑moves ranked top; DECIDE weights emphasize Compliance.
* **Low‑readiness scenario**: `build_readiness=0` → expect G6 (block heavy build), C/T moves ranked top.
* **Edge scenario**: `latency_edge=4` → expect G4; O/E edge moves prioritized; content\_tags include `edge`.
* **Data‑advantage scenario**: `data_advantage=4` → expect O/X moves (RAG, eval harness) prioritized.
* **No‑special constraints**: all zeros → few/no gates; X/E moves rise if pillar gaps are large.

---

## M. Appendix — Full CCP Questions (ready for copy/paste)

See Section **B** above for all 12 questions with anchors. Render as sliders 0–4 plus two Yes/No toggles and optional multi‑selects (functions, labels).

---

### Final Notes to the Developer

* Keep the CCP **simple and transparent**. The platform’s credibility depends on users seeing *why* your engine recommends what it recommends.
* Make thresholds **configurable** via an admin file so we can tune without redeploying.
* Build unit tests around the **gates** and **priority engine** first; the rest of the app can evolve.

If you want, I can also provide **mock JSON payloads** for several profile scenarios and a small **Move Library** seed (10–12 moves with tags and base scores) to bootstrap development.
